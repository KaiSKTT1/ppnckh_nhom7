{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11537403,"sourceType":"datasetVersion","datasetId":7235636}],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 15.2.1 Bagged Decision Trees\nfrom pandas import read_csv\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Đọc dữ liệu đúng cách\nfilename = '/kaggle/input/pima-indians-diabetes/diabetes.csv'\ndataframe = read_csv(filename)  # KHÔNG cần truyền `names=...`\n\nX = dataframe.iloc[:, :-1].values  # lấy tất cả các cột trừ cột cuối\nY = dataframe.iloc[:, -1].values   # lấy cột cuối (class/label)\n\n# Cấu hình\nseed = 7\nkfold = KFold(n_splits=10, shuffle=True, random_state=seed)\ncart = DecisionTreeClassifier()\nnum_trees = 100\nmodel = BaggingClassifier(estimator=cart, n_estimators=num_trees, random_state=seed)\n\n# Cross-validation\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(\"Độ chính xác trung bình:\", results.mean())\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-24T02:05:59.049076Z","iopub.execute_input":"2025-04-24T02:05:59.049393Z","iopub.status.idle":"2025-04-24T02:06:02.981516Z","shell.execute_reply.started":"2025-04-24T02:05:59.049370Z","shell.execute_reply":"2025-04-24T02:06:02.980549Z"}},"outputs":[{"name":"stdout","text":"Độ chính xác trung bình: 0.7578263841421736\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Random Forest Classification\nfrom pandas import read_csv\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestClassifier\n# Đọc dữ liệu đúng cách\nfilename = '/kaggle/input/pima-indians-diabetes/diabetes.csv'\ndataframe = read_csv(filename)  # KHÔNG cần truyền `names=...`\n\narray = dataframe.values\nX = array[:,0:8]\nY = array[:,8]\nnum_trees = 100\nmax_features = 3\nkfold = KFold(n_splits=10, shuffle=True, random_state=seed)\nmodel = RandomForestClassifier(n_estimators=num_trees, max_features=max_features)\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T02:10:14.401434Z","iopub.execute_input":"2025-04-24T02:10:14.401852Z","iopub.status.idle":"2025-04-24T02:10:16.724076Z","shell.execute_reply.started":"2025-04-24T02:10:14.401829Z","shell.execute_reply":"2025-04-24T02:10:16.722377Z"}},"outputs":[{"name":"stdout","text":"0.772112098427888\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Extra Trees Classification\nfrom pandas import read_csv\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import ExtraTreesClassifier\n# Đọc dữ liệu đúng cách\nfilename = '/kaggle/input/pima-indians-diabetes/diabetes.csv'\ndataframe = read_csv(filename)  # KHÔNG cần truyền `names=...`\n\narray = dataframe.values\nX = array[:,0:8]\nY = array[:,8]\nnum_trees = 100\nmax_features = 7\nkfold = KFold(n_splits=10, shuffle=True, random_state=seed)\nmodel = ExtraTreesClassifier(n_estimators=num_trees, max_features=max_features)\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T02:11:37.888991Z","iopub.execute_input":"2025-04-24T02:11:37.889328Z","iopub.status.idle":"2025-04-24T02:11:39.686857Z","shell.execute_reply.started":"2025-04-24T02:11:37.889307Z","shell.execute_reply":"2025-04-24T02:11:39.685849Z"}},"outputs":[{"name":"stdout","text":"0.7656015037593985\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# AdaBoost Classification\nfrom pandas import read_csv\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import AdaBoostClassifier\n# Đọc dữ liệu đúng cách\nfilename = '/kaggle/input/pima-indians-diabetes/diabetes.csv'\ndataframe = read_csv(filename)  # KHÔNG cần truyền `names=...`\narray = dataframe.values\nX = array[:,0:8]\nY = array[:,8]\nnum_trees = 30\nseed=7\nkfold = KFold(n_splits=10, shuffle=True, random_state=seed)\nmodel = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T02:12:34.311379Z","iopub.execute_input":"2025-04-24T02:12:34.311753Z","iopub.status.idle":"2025-04-24T02:12:34.952170Z","shell.execute_reply.started":"2025-04-24T02:12:34.311727Z","shell.execute_reply":"2025-04-24T02:12:34.951243Z"}},"outputs":[{"name":"stdout","text":"0.7552802460697198\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Stochastic Gradient Boosting Classification\nfrom pandas import read_csv\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import GradientBoostingClassifier\n# Đọc dữ liệu đúng cách\nfilename = '/kaggle/input/pima-indians-diabetes/diabetes.csv'\ndataframe = read_csv(filename)  # KHÔNG cần truyền `names=...`\narray = dataframe.values\nX = array[:,0:8]\nY = array[:,8]\nseed = 7\nnum_trees = 100\nkfold = KFold(n_splits=10, shuffle=True,random_state=seed)\nmodel = GradientBoostingClassifier(n_estimators=num_trees, random_state=seed)\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T02:13:38.446716Z","iopub.execute_input":"2025-04-24T02:13:38.447063Z","iopub.status.idle":"2025-04-24T02:13:40.161884Z","shell.execute_reply.started":"2025-04-24T02:13:38.447040Z","shell.execute_reply":"2025-04-24T02:13:40.160703Z"}},"outputs":[{"name":"stdout","text":"0.7591934381408066\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Voting Ensemble for Classification\nfrom pandas import read_csv\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import VotingClassifier\n# Đọc dữ liệu đúng cách\nfilename = '/kaggle/input/pima-indians-diabetes/diabetes.csv'\ndataframe = read_csv(filename)  # KHÔNG cần truyền `names=...`\narray = dataframe.values\nX = array[:,0:8]\nY = array[:,8]\nkfold = KFold(n_splits=10,shuffle=True, random_state=7)\n# create the sub models\nestimators = []\nmodel1 = LogisticRegression()\nestimators.append(('logistic', model1))\nmodel2 = DecisionTreeClassifier()\nestimators.append(('cart', model2))\nmodel3 = SVC()\nestimators.append(('svm', model3))\n# create the ensemble model\nensemble = VotingClassifier(estimators)\nresults = cross_val_score(ensemble, X, Y, cv=kfold)\nprint(results.mean())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T02:14:58.888133Z","iopub.execute_input":"2025-04-24T02:14:58.888448Z","iopub.status.idle":"2025-04-24T02:15:04.457782Z","shell.execute_reply.started":"2025-04-24T02:14:58.888425Z","shell.execute_reply":"2025-04-24T02:15:04.455097Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"0.7708646616541354\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"}],"execution_count":28}]}